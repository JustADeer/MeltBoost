{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113155,"databundleVersionId":13473948,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13248875,"sourceType":"datasetVersion","datasetId":8364474}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Installing Plugins\nInstalls GPU and CPU libs","metadata":{}},{"cell_type":"code","source":"# Add RAPIDS to do training faster\n# Run if on GPU\n\n!pip install cudf-cu12 --extra-index-url=https://pypi.nvidia.com\n%load_ext cudf.pandas\nclear_output()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install rdkit\n!pip install optuna\n!pip install optuna-integration[xgboost]\n!pip install swifter\n!pip install tdqm\n!pip install shap\n!pip install jax[cuda12]\n!pip install umap-learn\n!pip install pyscf\nclear_output()\nprint('Finished installing pre-requisites')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:45:11.360949Z","iopub.execute_input":"2025-10-29T06:45:11.361277Z","iopub.status.idle":"2025-10-29T06:46:10.047527Z","shell.execute_reply.started":"2025-10-29T06:45:11.361251Z","shell.execute_reply":"2025-10-29T06:46:10.046205Z"}},"outputs":[{"name":"stdout","text":"Collecting rdkit\n  Downloading rdkit-2025.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit) (2024.2.0)\nDownloading rdkit-2025.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (36.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rdkit\nSuccessfully installed rdkit-2025.9.1\nRequirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.5.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.5)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\nCollecting optuna-integration[xgboost]\n  Downloading optuna_integration-4.5.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optuna-integration[xgboost]) (4.5.0)\nRequirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from optuna-integration[xgboost]) (2.0.3)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (1.16.5)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (2.0.41)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (6.0.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost->optuna-integration[xgboost]) (1.15.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[xgboost]) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[xgboost]) (4.15.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[xgboost]) (3.2.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna->optuna-integration[xgboost]) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration[xgboost]) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna->optuna-integration[xgboost]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna->optuna-integration[xgboost]) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna->optuna-integration[xgboost]) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna->optuna-integration[xgboost]) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna->optuna-integration[xgboost]) (2024.2.0)\nDownloading optuna_integration-4.5.0-py3-none-any.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: optuna-integration\nSuccessfully installed optuna-integration-4.5.0\nCollecting swifter\n  Downloading swifter-1.4.0.tar.gz (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from swifter) (2.2.3)\nRequirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.11/dist-packages (from swifter) (7.1.0)\nRequirement already satisfied: dask>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2024.12.1)\nRequirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from swifter) (4.67.1)\nRequirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.3.0)\nRequirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.1.1)\nRequirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2025.9.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (25.0)\nRequirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.2)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (6.0.3)\nRequirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\nRequirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.7.0)\nRequirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.1.21)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (2025.2)\nRequirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]>=2.10.0->swifter) (19.0.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->swifter) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->swifter) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->swifter) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->swifter) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->swifter) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->swifter) (2.4.1)\nRequirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas>=1.0.0->swifter) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas>=1.0.0->swifter) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas>=1.0.0->swifter) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas>=1.0.0->swifter) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas>=1.0.0->swifter) (2024.2.0)\nBuilding wheels for collected packages: swifter\n  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16505 sha256=a1580aefcb02c68738a961b24fdf334cae60beba964e747e9ec859a593d6f903\n  Stored in directory: /root/.cache/pip/wheels/ef/7f/bd/9bed48f078f3ee1fa75e0b29b6e0335ce1cb03a38d3443b3a3\nSuccessfully built swifter\nInstalling collected packages: swifter\nSuccessfully installed swifter-1.4.0\nCollecting tdqm\n  Downloading tdqm-0.0.1.tar.gz (1.4 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tdqm) (4.67.1)\nBuilding wheels for collected packages: tdqm\n  Building wheel for tdqm (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for tdqm: filename=tdqm-0.0.1-py3-none-any.whl size=1322 sha256=ff1d557356b19d564683230ccbc34bb483c80a92c2699ca3a779721ee706a897\n  Stored in directory: /root/.cache/pip/wheels/c8/c7/30/e5935be2cfa6883be72462333edc414d8928f3c78eaabec38a\nSuccessfully built tdqm\nInstalling collected packages: tdqm\nSuccessfully installed tdqm-0.0.1\nRequirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.44.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.3)\nRequirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\nRequirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (25.0)\nRequirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.7)\nRequirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->shap) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->shap) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->shap) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->shap) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->shap) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->shap) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->shap) (2024.2.0)\nRequirement already satisfied: jax[cuda12] in /usr/local/lib/python3.11/dist-packages (0.5.2)\nRequirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax[cuda12]) (0.5.1)\nRequirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax[cuda12]) (0.4.1)\nRequirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from jax[cuda12]) (1.26.4)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax[cuda12]) (3.4.0)\nRequirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax[cuda12]) (1.15.3)\nRequirement already satisfied: jax-cuda12-plugin<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (0.5.1)\nRequirement already satisfied: jax-cuda12-pjrt==0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin<=0.5.2,>=0.5.1->jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (0.5.1)\nRequirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (12.5.3.2)\nRequirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (12.5.82)\nCollecting nvidia-cuda-nvcc-cu12>=12.6.85 (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12])\n  Downloading nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (12.5.82)\nRequirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.1 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (9.3.0.75)\nRequirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (11.2.3.61)\nRequirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (11.6.3.83)\nRequirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (12.5.1.3)\nRequirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (2.21.5)\nRequirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.5.2,>=0.5.1; extra == \"cuda12\"->jax[cuda12]) (12.5.82)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->jax[cuda12]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->jax[cuda12]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->jax[cuda12]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->jax[cuda12]) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->jax[cuda12]) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->jax[cuda12]) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.25->jax[cuda12]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.25->jax[cuda12]) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.25->jax[cuda12]) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.25->jax[cuda12]) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.25->jax[cuda12]) (2024.2.0)\nDownloading nvidia_cuda_nvcc_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cuda-nvcc-cu12\n  Attempting uninstall: nvidia-cuda-nvcc-cu12\n    Found existing installation: nvidia-cuda-nvcc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvcc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvcc-cu12-12.5.82\nSuccessfully installed nvidia-cuda-nvcc-cu12-12.9.86\nRequirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.9.post2)\nRequirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (1.15.3)\nCollecting scikit-learn>=1.6 (from umap-learn)\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.60.0)\nRequirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from umap-learn) (4.67.1)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->umap-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->umap-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->umap-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->umap-learn) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->umap-learn) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23->umap-learn) (2.4.1)\nRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from pynndescent>=0.5->umap-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6->umap-learn) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23->umap-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23->umap-learn) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23->umap-learn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23->umap-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23->umap-learn) (2024.2.0)\nDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikit-learn-1.7.2\nCollecting pyscf\n  Downloading pyscf-2.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: numpy!=1.16,!=1.17,>=1.13 in /usr/local/lib/python3.11/dist-packages (from pyscf) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pyscf) (1.15.3)\nRequirement already satisfied: h5py>=2.7 in /usr/local/lib/python3.11/dist-packages (from pyscf) (3.14.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyscf) (75.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.16,!=1.17,>=1.13->pyscf) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.16,!=1.17,>=1.13->pyscf) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.16,!=1.17,>=1.13->pyscf) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.16,!=1.17,>=1.13->pyscf) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.16,!=1.17,>=1.13->pyscf) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.16,!=1.17,>=1.13->pyscf) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.16,!=1.17,>=1.13->pyscf) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.16,!=1.17,>=1.13->pyscf) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.16,!=1.17,>=1.13->pyscf) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.16,!=1.17,>=1.13->pyscf) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.16,!=1.17,>=1.13->pyscf) (2024.2.0)\nDownloading pyscf-2.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (51.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyscf\nSuccessfully installed pyscf-2.11.0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/652454152.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install umap-learn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install pyscf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished installing pre-requisites'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'clear_output' is not defined"],"ename":"NameError","evalue":"name 'clear_output' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# Calculations Libs\nimport numpy as np\nimport cupy as cp\nimport pandas as pd\nimport jax\nfrom jax import numpy as jnp\nimport swifter\n\n# Hardware\nimport gc\n\n# Disable Warning\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Disable Warning From rdkit\nfrom rdkit import RDLogger\nRDLogger.DisableLog('rdApp.*')\n\n# Descriptor Libs\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem, Descriptors3D, Descriptors, Crippen, rdMolDescriptors, MACCSkeys, RDKFingerprint, rdFingerprintGenerator\nfrom rdkit.Chem.MolStandardize import rdMolStandardize\nfrom rdkit.Avalon import pyAvalonTools\nfrom rdkit.Chem.rdForceFieldHelpers import MMFFOptimizeMoleculeConfs as MMFFOp\nfrom rdkit.Chem.rdForceFieldHelpers import UFFOptimizeMoleculeConfs as UFFOp\nfrom rdkit.Chem.rdForceFieldHelpers import MMFFHasAllMoleculeParams\n\nimport pyscf\nfrom pyscf import gto, scf, dft\n\n# Model processing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nimport umap\n\n# Machine Learning Libs\nimport xgboost\nimport lightgbm as lgb\n\n# Training Op Libs\nimport optuna\n\n# Visualize Libs\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Tools Libs\nfrom joblib import Parallel, delayed, dump\nfrom joblib import load as jload\nfrom tqdm.notebook import tqdm\n\nprint('Finnished Importing Plugins!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:46:34.110199Z","iopub.execute_input":"2025-10-29T06:46:34.110883Z","iopub.status.idle":"2025-10-29T06:47:22.350458Z","shell.execute_reply.started":"2025-10-29T06:46:34.110851Z","shell.execute_reply":"2025-10-29T06:47:22.349488Z"}},"outputs":[{"name":"stderr","text":"2025-10-29 06:47:00.759650: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761720421.005380      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761720421.081682      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Finnished Importing Plugins!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Load Data\nLoad data from Kaggle into a pandas DataFrame.","metadata":{}},{"cell_type":"code","source":"raw_train = pd.read_csv('/kaggle/input/melting-point/train.csv')\nraw_test = pd.read_csv('/kaggle/input/melting-point/test.csv')\n\nbradley_df = pd.read_csv(r'/kaggle/input/melting-point-chemical-dataset/BradleyMeltingPointDataset.csv')\nbradleyplus_df = pd.read_csv(r'/kaggle/input/melting-point-chemical-dataset/BradleyDoublePlusGoodMeltingPointDataset.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert from Celcius (mpC) to Kelvin (Tm)\nbradley_df['Tm'] = bradley_df['mpC'].apply(lambda x: x + 273)\nbradleyplus_df['Tm'] = bradleyplus_df['mpC'].apply(lambda x: x + 273)\n\n# Get only SMILES and Melting Tempature (Tm)\n# Merge both bradle datasets\nbradley_merge = pd.concat((\n    bradley_df[['smiles', 'Tm']],\n    bradleyplus_df[['smiles', 'Tm']]\n), axis=0)\nbradley_merge = bradley_merge.rename(columns = {'smiles': 'SMILES'})\n\nbradley_merge","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Merge both datasets to one\ntrain_df = pd.concat((\n    raw_train[['SMILES', 'Tm']], \n    bradley_merge\n), axis=0)\n\ntest_df = raw_test[['id', 'SMILES']]\n\ndisplay(train_df, test_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Canonical SMILES\nChange all SMILES to they're *canonical* counterparts to remove duplicated samples. The problem with this is difference in samples between datasets, when calculated the *SMILES* counterpart, then the duplicate process runs it detects the same canonical *SMILES* but with different *Tm* (Melting point). We handle this with just choosing one of them. Have not found a better solution for this problem. But, more than 85% of the duplicated data has a variance average of lower than 6° Kelvin. But due to different ways of measureing tempatures in different datasets available, 5% of the samples have large variance more than 25° Kelvin which is dropped due to inconssistent data to not feed the model unrelated data.\n\nThe *canonical_smiles_variance* function also calculate the mol and 3d mol for future mol calculations.","metadata":{}},{"cell_type":"code","source":"def generate_3d_conformer(mol_2d: Chem.Mol, random_seed: int = 42) -> Chem.Mol | None:\n    \"\"\"\n    Robustly generate a 3D conformer for an RDKit Mol object.\n\n    Handles:\n      - Hydrogen addition\n      - Modern ETKDGv3 embedding\n      - **Multiple conformer generation attempts (numConfs=10)**\n      - **Optimization of all conformers**\n      - MMFF vs UFF optimization fallback\n      - **Selection of the lowest-energy conformer**\n      - Reproducible random seed\n\n    Returns:\n      mol3d (RDKit Mol with one 3D conformer) or None if failed.\n    \"\"\"\n    \n    # Create a new molecule object and add hydrogens\n    # This is crucial for getting a correct 3D geometry\n    mol = Chem.AddHs(mol)\n\n    # Set up the modern ETKDGv3 embedding parameters\n    params = AllChem.ETKDGv3()\n    params.randomSeed = random_seed\n    params.useRandomCoords = True # Use random starting coordinates\n    params.numThreads = 0 # Use all available CPU cores\n    \n    # Attempt to embed multiple conformers\n    # This is more robust than a single EmbedMolecule call.\n    cids = AllChem.EmbedMultipleConfs(mol, numConfs=10, params=params)\n\n    if len(cids) == 0:\n        print(f\"Failed to embed any conformers for molecule: {Chem.MolToSmiles(mol_2d)}\")\n        return None\n\n    # Optimize the geometries\n    # We prefer the MMFF94 force field, but fall back to UFF.\n    # We optimize all generated conformers (cids).\n    energies = []\n    try:\n        if MMFFHasAllMoleculeParams(mol):\n            # MMFFOptimizeMoleculeConfs returns list of (not_converged, energy)\n            results = MMFFOp(mol, numThreads=0)\n            energies = [res for res in results if res[0] == 0] # Filter for converged\n        else:\n            # Use UFF as a fallback\n            results = UFFOp(mol, numThreads=0)\n            energies = [res for res in results if res[0] == 0] # Filter for converged\n\n    except Exception as e:\n        # Catch any other optimization errors and try UFF\n        print(f\"MMFF optimization failed ({e}), falling back to UFF.\")\n        try:\n            results = UFFOp(mol, numThreads=0)\n            energies = [res for res in results if res[0] == 0] # Filter for converged\n        except Exception as e_uff:\n            print(f\"UFF optimization also failed: {e_uff}\")\n            # We might still have cids, but optimization failed.\n            pass # Continue, we might have some unoptimized energies if needed, or just fail\n\n    if not energies:\n        print(f\"All conformer optimizations failed for: {Chem.MolToSmiles(mol_2d)}\")\n        # As a last resort, we could return the unoptimized conformer, \n        # but for robustness, it's better to signal failure.\n        return None\n\n    # Find the conformer with the lowest energy\n    # energies is a list of (conformer_id, energy)\n    sorted_energies = sorted(energies, key=lambda x: x[1])\n    best_cid = sorted_energies[0][0]\n    best_energy = sorted_energies[0][1]\n\n    # print(f\"Found best conformer (ID {best_cid}) with energy: {best_energy:.2f}\")\n\n    # Create a new molecule to hold only the best conformer\n    final_mol = Chem.Mol(mol)\n    final_mol.RemoveAllConformers()\n    \n    # Get the specific conformer from the original molecule\n    best_conf = mol.GetConformer(best_cid)\n    final_mol.AddConformer(best_conf, assignId=True)\n    \n    return final_mol","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def canonical_smiles_variance(canonical_df, target_col='Tm', low_thr=5, high_thr=25):\n    df = canonical_df.copy()\n\n    # --- Ensure target column is numeric ---\n    df[target_col] = pd.to_numeric(df[target_col], errors='coerce')\n    df = df.dropna(subset=[target_col])\n\n    # --- Handle duplicates only ---\n    dups = df[df['SMILES'].duplicated(keep=False)]\n    uniq = df[~df['SMILES'].duplicated(keep=False)]\n\n    if dups.empty:\n        print(\"No duplicates found after canonicalization.\")\n        return df, pd.DataFrame()\n\n    stats = (\n        dups.groupby('SMILES')[target_col]\n        .agg(['mean', 'median', 'std', 'count'])\n        .reset_index()\n    )\n\n    # --- Merge duplicates based on variance thresholds ---\n    stats['value'] = stats.apply(\n        lambda r: r['mean'] if r['std'] < low_thr\n        else r['median'] if r['std'] <= high_thr\n        else None, axis=1\n    )\n\n    merged_df = stats.dropna(subset=['value'])[['SMILES', 'value']]\n    merged_df = merged_df.rename(columns={'value': target_col})\n\n    # Reattach Mol objects for merged entries\n    merged_df['Mol'] = merged_df['SMILES'].map(\n        df.drop_duplicates('SMILES').set_index('SMILES')['Mol']\n    )\n\n    # Combine merged + unique\n    cleaned = pd.concat([uniq[['SMILES', target_col, 'Mol']], merged_df], ignore_index=True)\n    cleaned = cleaned.reset_index(drop=True)\n\n    print(f\"Original: {df.shape[0]} rows\")\n    print(f\"Unique:   {uniq.shape[0]}\")\n    print(f\"Merged:   {len(merged_df)}\")\n    print(f\"Dropped Varience:  {stats.shape[0] - len(merged_df)} (high variance > {high_thr} K)\")\n\n    display(\n        cleaned,\n        cleaned.info(),\n        stats,\n        cleaned['SMILES'].isna().value_counts()\n    )\n\n    return cleaned, stats","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def canonicalize_smiles_df(df, stat=False):\n    \"\"\"\n    Converts SMILES strings in a DataFrame to their canonical form.\n\n    This function performs the following steps:\n    1. Creates a copy of the DataFrame.\n    2. Converts SMILES strings from 'smiles_col' to RDKit Mol objects\n       and stores them in a new 'Mol' column.\n    3. Drops any rows where the SMILES string was invalid (Mol is None).\n    4. Converts the 'Mol' objects back to canonical SMILES strings,\n       updating 'smiles_col' in place.\n    \n    This is a simplified version of your original function, removing\n    all statistics calculation, duplicate merging, and 3D structure generation.\n\n    Args:\n        df (pd.DataFrame): The input DataFrame.\n        smiles_col (str): The name of the column containing SMILES strings.\n                          Defaults to 'SMILES'.\n\n    Returns:\n        pd.DataFrame: A new DataFrame with canonical SMILES, a 'Mol' column,\n                      and invalid SMILES rows removed.\n    \"\"\"\n    # Suppress RDKit errors (like for 'invalid-smiles') during Mol conversion\n    \n    df_copy = df.copy()\n\n    print(\"Step 1: Converting SMILES to Mol objects...\")\n    # --- Convert to Mol objects (keep them) ---\n    mol_series = df_copy['SMILES'].swifter.apply(Chem.MolFromSmiles)\n    df_copy['Mol'] = mol_series\n\n    # --- Drop rows where Mol conversion failed ---\n    initial_rows = df_copy.shape[0]\n    df_copy = df_copy.dropna(subset=['Mol']).reset_index(drop=True)\n    dropped_rows = initial_rows - df_copy.shape[0]\n    \n    if dropped_rows > 0:\n        print(f\"Step 2: Dropped {dropped_rows} rows due to invalid/unparseable SMILES.\")\n    else:\n        print(\"Step 2: All SMILES strings parsed successfully.\")\n\n    print(\"Step 3: Canonicalizing SMILES strings...\")\n    # --- Canonicalize SMILES (Mol remains valid) ---\n    # Note: isomericSmiles=True is kept from the original to preserve stereochemistry\n    canonical_smiles_series = df_copy['Mol'].swifter.apply(\n        lambda m: Chem.MolToSmiles(m, canonical=True, isomericSmiles=True)\n    )\n\n    df_copy['SMILES'] = canonical_smiles_series\n    \n    print(\"Canonicalization complete.\")\n\n    #print(\"Step 4: Generating 3D Mol...\")\n    #df_copy['Mol3D'] = df_copy['Mol'].apply(generate_3d_conformer)\n    #df_copy = df_copy[df_copy['Mol3D'].notnull()]\n    #df_copy = df_copy.reset_index(drop=True)\n    if stat == True:\n        df_copy, stats = canonical_smiles_variance(df_copy)\n        return df_copy, stats\n    else:\n        return df_copy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, stats = canonicalize_smiles_df(train_df, stat=True)\ntest_df = canonicalize_smiles_df(test_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Visualize variance of melting tempature of duplicated SMILES","metadata":{}},{"cell_type":"code","source":"def plot_tm_variance_colored(variance_df):\n    stds = variance_df['std'].dropna()\n\n    # Define bins\n    bins = np.linspace(0, stds.max(), 60)\n\n    plt.figure(figsize=(10, 6))\n    n, bins, patches = plt.hist(stds, bins=bins, edgecolor='black', alpha=0.8)\n\n    # Color-code regions\n    for patch, left_edge in zip(patches, bins[:-1]):\n        if left_edge < 5:\n            patch.set_facecolor('green')\n        elif left_edge < 25:\n            patch.set_facecolor('gold')\n        else:\n            patch.set_facecolor('red')\n\n    plt.title('Variance in Melting Points Across Duplicate Canonical SMILES')\n    plt.xlabel('Standard Deviation (K)')\n    plt.ylabel('Number of Molecules')\n    plt.axvline(5, color='black', linestyle='--', label='5 K (good threshold)')\n    plt.axvline(25, color='red', linestyle='--', label='25 K (large variance)')\n    plt.legend()\n    plt.grid(alpha=0.3)\n    plt.show()\n\ndef summarize_variance_plot(variance_df, show_pie=False):\n    # Clean data\n    stds = variance_df['std'].dropna()\n    total = len(stds)\n\n    # Define categories\n    categories = {\n        'Excellent (<5 K)': (stds < 5).sum(),\n        'Moderate (5–25 K)': ((stds >= 5) & (stds <= 25)).sum(),\n        'High (>25 K)': (stds > 25).sum()\n    }\n\n    # Convert to percentages\n    labels = list(categories.keys())\n    values = [v / total * 100 for v in categories.values()]\n    \n    # --- Visualization ---\n    plt.figure(figsize=(7, 5))\n\n    if show_pie:\n        # Pie chart\n        plt.pie(\n            values,\n            labels=labels,\n            autopct='%1.1f%%',\n            startangle=140,\n            colors=['green', 'gold', 'red']\n        )\n        plt.title('Melting Point Variance Summary (by Category)')\n    else:\n        # Bar chart\n        plt.bar(labels, values, color=['green', 'gold', 'red'], edgecolor='black')\n        plt.title('Melting Point Variance Summary')\n        plt.ylabel('Percentage of Duplicates (%)')\n        plt.grid(axis='y', alpha=0.3)\n\n    plt.tight_layout()\n    plt.show()\n\nsummarize_variance_plot(stats, show_pie=True)\nplot_tm_variance_colored(stats)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Calculate the Descriptors of the molecules.","metadata":{}},{"cell_type":"code","source":"def extract_2d_desc(df: pd.DataFrame) -> pd.DataFrame:\n    if 'Mol' not in df.columns:\n        df['Mol'] = df['SMILES'].swifter.apply(Chem.MolFromSmiles)\n    desc_features = pd.DataFrame(\n        Parallel(n_jobs=-1)(\n            delayed(Descriptors.CalcMolDescriptors)(mol) for mol in tqdm(df['Mol'], desc=\"Calculating 2D descriptors\")\n        )\n    )\n    \n    return pd.concat([df, desc_features], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_3d_desc(df: pd.DataFrame) -> pd.DataFrame:\n    if 'Mol3D' not in df.columns:\n        df['Mol3D'] = df['Mol'].swifter.apply(generate_3d_mol)\n        df = df[df['Mol3D'].notnull()]\n    desc_features = pd.DataFrame(\n        Parallel(n_jobs=-1)(\n            delayed(Descriptors3D.CalcMolDescriptors3D)(mol) for mol in tqdm(df['Mol3D'], desc=\"Calculating 3D descriptors\")\n        )\n    )\n    \n    return pd.concat([df, desc_features], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_fingerprint(df: pd.DataFrame, morgan_radius = 2, morgan_nbits = 1024, train=False) -> pd.DataFrame:\n    if 'Mol' not in df.columns:\n        df['Mol'] = df['SMILES'].apply(Chem.MolFromSmiles)\n\n    # DEFINE MORGAN GENERATOR\n    morgan_gen = rdFingerprintGenerator.GetMorganGenerator(\n        radius = morgan_radius, \n        fpSize = morgan_nbits, \n        countSimulation = True, \n        includeChirality = False\n    )\n\n    fcfp_gen = rdFingerprintGenerator.GetMorganGenerator(\n        radius = morgan_nbits, \n        fpSize = morgan_nbits, \n        atomInvariantsGenerator = rdFingerprintGenerator.GetMorganFeatureAtomInvGen(), \n        countSimulation= True, \n        includeChirality = False\n    )\n\n    atom_gen = rdFingerprintGenerator.GetAtomPairGenerator(\n        fpSize = 2048, \n        countSimulation= True, \n        includeChirality = False\n    )\n\n    # Helper: convert a single molecule into all fingerprints\n    def get_all_fps(mol):\n        if mol is None:\n            # Return zero arrays to preserve shape\n            return [\n                np.zeros(morgan_nbits),\n                np.zeros(morgan_nbits),\n                np.zeros(167),        # MACCS\n                np.zeros(2048),\n                np.zeros(2048),\n                np.zeros(morgan_nbits)\n            ]\n        return [\n            morgan_gen.GetFingerprintAsNumPy(mol),\n            fcfp_gen.GetFingerprintAsNumPy(mol),\n            np.array(list(MACCSkeys.GenMACCSKeys(mol).ToBitString()), dtype=np.uint8),\n            atom_gen.GetCountFingerprintAsNumPy(mol),\n            np.fromiter(RDKFingerprint(mol).ToBitString(), dtype=np.uint8),\n            pyAvalonTools.GetAvalonFP(mol, morgan_nbits)\n        ]\n    \n    # 1. Convert each fingerprint Series to a NumPy array\n    fps = df['Mol'].swifter.apply(get_all_fps)\n\n    # 2. Combine all NumPy arrays horizontally in one operation 🚀\n    # np.hstack is extremely fast and memory-efficient\n        # Stack each fingerprint type separately\n    morgan_arr = np.vstack([f[0] for f in fps])\n    fcfp_arr = np.vstack([f[1] for f in fps])\n    maccs_arr = np.vstack([f[2] for f in fps])\n    atom_arr = np.vstack([f[3] for f in fps])\n    rdkit_arr = np.vstack([f[4] for f in fps])\n    avalon_arr = np.vstack([f[5] for f in fps])\n\n    # Combine all arrays horizontally\n    combined_arr = np.hstack([morgan_arr, fcfp_arr, maccs_arr, atom_arr, rdkit_arr, avalon_arr])\n    \n    # Column Names\n    combined_cols = [\n        [f'morg_{i}' for i in range(morgan_arr.shape[1])] +\n        [f'fcfp_{i}' for i in range(fcfp_arr.shape[1])] +\n        [f'maccs_{i}' for i in range(maccs_arr.shape[1])] +\n        [f'atom_{i}' for i in range(atom_arr.shape[1])] +\n        [f'rdkit_{i}' for i in range(rdkit_arr.shape[1])] +\n        [f'avalon_{i}' for i in range(avalon_arr.shape[1])]\n    ]\n\n    if train:\n        umap_transformer = umap.UMAP(\n            n_components=100,\n            n_neighbors=15,\n            min_dist=0.1,\n            random_state=42, # Always set a seed for reproducibility!\n            metric='jaccard', # Binary Metric https://umap-learn.readthedocs.io/en/latest/parameters.html#metric\n        )\n        \n        umap_transformer.fit(combined_arr)\n        dump(umap_transformer, 'fp_umap.pkl', compress=3)\n    else:\n        umap_transformer = jload('fp_umap.pkl')\n    \n    ca_UMAP = umap_transformer.transform(combined_arr)\n    ca_Col = [f'umap_{i}' for i in range(100)]\n    \n    print(f\"Original shape: {combined_arr.shape}\")\n    print(f\"New UMAP feature shape: {ca_UMAP.shape}\")\n    \n    # 4. Create the final DataFrame from the combined array and column names\n    return pd.concat([df, pd.DataFrame(ca_UMAP, columns=ca_Col)], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## *Analyzing fastest apply method :3*\nThe test was done with the *get_2D_desc*\n### Normal .apply()\n    CPU times: user 3min 50s, sys: 2.14 s, total: 3min 52s\n    Wall time: 2min 38s\n\n### Swifter .apply()\n    CPU times: user 4min 5s, sys: 2.03 s, total: 4min 7s\n    Wall time: 2min 44s\n\n### List comprehension\n    CPU times: user 3min 45s, sys: 787 ms, total: 3min 46s\n    Wall time: 2min 32s\n\n### List comprehension Multithreaded:\n    CPU times: user 11.4 s, sys: 1.14 s, total: 12.6 s\n    Wall time: 59.9 s","metadata":{}},{"cell_type":"code","source":"def removena(df):\n    # DROP NULL/NONE VALUE AFTER FEATURE ENGINEERING\n    return df.copy().dropna().reset_index(drop = True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nfinal_train_df = train_df.copy()\nfinal_test_df = test_df.copy()\n\nfinal_train_df = extract_2d_desc(final_train_df)\nfinal_test_df = extract_2d_desc(final_test_df)\n\n# final_train_df = extract_3d_desc(final_train_df)\n# final_test_df = extract_3d_desc(final_test_df)\n\n# Remember to train first\nfinal_train_df = extract_fingerprint(final_train_df, train=True)\nfinal_test_df = extract_fingerprint(final_test_df)\n\nfinal_train_df = removena(final_train_df)\nfinal_test_df = removena(final_test_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(\n    final_train_df,\n    final_train_df.info(),\n    final_test_df, \n    final_test_df.info()\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DROP DUPLICATED FROM MERGED DATA\ndef drop_dup(df):\n    display(f'There are {df.duplicated(subset = [\"SMILES\", \"Tm\"]).sum()} Duplicated data')\n    df = df.drop_duplicates(subset = ['SMILES', 'Tm']).reset_index(drop = True)\n    print(f'Successfully dropped Duplicated data based on SMILES and Tm!\\n\\n')\n    \n    display(f'There are {df.duplicated(subset = [\"SMILES\"]).sum()} duplicated rows based on SMILES')\n    df = df.drop_duplicates(subset = ['SMILES'], keep='first').reset_index(drop = True)\n    print(f'Successfully dropped duplicated rows based on SMILES!')\n\n    return df\n\n# Dont really need to use!","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def reduce_memory_usage(df: pd.DataFrame, use_unsigned=True, verbose=True) -> pd.DataFrame:\n    \"\"\"\n    Downcast numeric columns in a DataFrame to the smallest possible dtype.\n    Optionally converts non-negative integers to unsigned types.\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Input DataFrame\n    use_unsigned : bool\n        Whether to allow unsigned integer types (uint8/16/32/64) when all values >= 0\n    verbose : bool\n        Whether to print memory usage statistics\n    \n    Returns\n    -------\n    pd.DataFrame\n        Memory-optimized DataFrame\n    \"\"\"\n    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n    if verbose:\n        print(f\"Initial memory usage: {start_mem:.2f} MB\")\n\n    for col in df.select_dtypes(include=[np.number]).columns:\n        try:\n            col_type = df[col].dtype\n        except:\n            display('dtype error skipping...')\n            return df\n        c_min, c_max = df[col].min(), df[col].max()\n\n        if np.issubdtype(col_type, np.integer):\n            # Use unsigned types when possible\n            if use_unsigned and c_min >= 0:\n                if c_max < np.iinfo(np.uint8).max:\n                    df[col] = df[col].astype(np.uint8)\n                elif c_max < np.iinfo(np.uint16).max:\n                    df[col] = df[col].astype(np.uint16)\n                elif c_max < np.iinfo(np.uint32).max:\n                    df[col] = df[col].astype(np.uint32)\n                else:\n                    df[col] = df[col].astype(np.uint64)\n            else:\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                else:\n                    df[col] = df[col].astype(np.int64)\n\n        elif np.issubdtype(col_type, np.floating):\n            df[col] = pd.to_numeric(df[col], downcast=\"float\")\n\n    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n    if verbose:\n        reduction = 100 * (start_mem - end_mem) / start_mem\n        print(f\"Reduced memory usage: {end_mem:.2f} MB ({reduction:.1f}% reduction)\")\n\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = final_train_df.drop(columns=['SMILES', 'Tm', 'Mol'])\ny = final_train_df['Tm']\n\nsub = final_test_df.drop(columns=['SMILES', 'id', 'Mol'])\nsub = sub.reindex(columns=X.columns, fill_value=0)\nassert all(sub.columns == X.columns), \"Column order mismatch!\"\nprint(\"✅ Columns are now aligned with training data.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.columns = X.columns.astype(str)\n\nselector = VarianceThreshold(threshold=0.01).fit(X)\n\n\nfeatures_mask = selector.get_support()\nfeatures_names = X.columns[features_mask]\n\nX_sel_np = selector.transform(X)\nsub_sel_np = selector.transform(sub)\n\nprint('Finishing variance filter...')\n\nX = pd.DataFrame(X_sel_np, columns=features_names)\nsub = pd.DataFrame(sub_sel_np, columns=features_names)\n\nX = reduce_memory_usage(X)\nsub = reduce_memory_usage(sub)\n\nX.to_hdf('training.h5', key='data', mode='w', format='table', index=False)\ny.to_hdf('test.h5', key='data', mode='w', format='table', index=False)\n\nsub.to_hdf('submission.h5', key='data', mode='w', format='table', index=False)\n\nprint('Finishing saving...')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Jax eval function\nUse JAX to use the *just-in-time* (**JIT**) feature to evaluate the metrics faster. I don't what are the overhead of using JAX in this case.","metadata":{}},{"cell_type":"code","source":"class metrics:\n    class regression:\n        \"\"\"Regression metrics (MAE, MSE, RMSE, R²).\"\"\"\n\n        @staticmethod\n        @jax.jit\n        def mean_absolute_error(\n            y_pred: jnp.ndarray, y_true: jnp.ndarray\n        ) -> jnp.ndarray:\n            \"\"\"Mean Absolute Error (MAE)\"\"\"\n            return jnp.mean(jnp.abs(y_pred - y_true))\n\n        @staticmethod\n        @jax.jit\n        def mean_squared_error(y_pred: jnp.ndarray, y_true: jnp.ndarray) -> jnp.ndarray:\n            \"\"\"Mean Squared Error (MSE)\"\"\"\n            return jnp.mean((y_pred - y_true) ** 2)\n\n        @staticmethod\n        @jax.jit\n        def root_mean_squared_error(\n            y_pred: jnp.ndarray, y_true: jnp.ndarray\n        ) -> jnp.ndarray:\n            \"\"\"Root Mean Squared Error (RMSE)\"\"\"\n            return jnp.sqrt(jnp.mean((y_pred - y_true) ** 2))\n\n        @staticmethod\n        @jax.jit\n        def r2_score(y_pred: jnp.ndarray, y_true: jnp.ndarray) -> jnp.ndarray:\n            \"\"\"Coefficient of Determination (R²)\"\"\"\n            ss_res = jnp.sum((y_true - y_pred) ** 2)\n            ss_tot = jnp.sum((y_true - jnp.mean(y_true)) ** 2)\n            return jnp.where(ss_tot == 0, 0.0, 1 - ss_res / ss_tot)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport timeit\n\nx1 = np.random.rand(1, 200)\nx2 = np.random.rand(1, 200)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nt = timeit.timeit(lambda: metrics.regression.root_mean_squared_error(jnp.array(x1), jnp.array(x2)), number=1000)\nprint(\"Avg time per run:\", t / 1000)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\nt = timeit.timeit(lambda: np.sqrt(mean_squared_error(x1, x2)), number=1000)\nprint(\"Avg time per run:\", t / 1000)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Use a gpu from this point onwards!!!\nWe will use the cuda cores so if you are still in a *CPU session* this will not work!!!","metadata":{}},{"cell_type":"code","source":"xgboost.set_config(enable_pinned_memory=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = pd.read_hdf('training.h5', key='data')\ny = pd.read_hdf('test.h5', key='data')\n\ndisplay(X, y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from optuna.integration import XGBoostPruningCallback\n\ndef objective(trial) -> float:\n    param = {\n        'verbosity': 0,\n        'objective': 'reg:squarederror',\n        'device': 'cuda', # USE CUDA ACCELERATION\n        'tree_method': 'gpu_hist',\n        'predictor': 'gpu_predictor',\n        'n_gpus': -1,\n        'eval_metric': 'rmse',\n        'n_estimators': 10_000,\n        'booster': 'gbtree',\n        \"grow_policy\": \"lossguide\",  # often improves chem-space generalization\n        \n        'learning_rate': trial.suggest_float('learning_rate', 3e-3, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 4,9),\n        \n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 6),\n        'max_delta_step': trial.suggest_float('max_delta_step', 0, 10),\n        \n        'subsample': trial.suggest_float('subsample', 0.65, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.65, 1.0),\n        \n        'gamma': trial.suggest_float('gamma', 0, 3),\n        'lambda': trial.suggest_float('lambda', 0.1, 20.0, log=True),\n        'alpha': trial.suggest_float('alpha', 0.1, 20.0, log=True),\n    }\n\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    kf_indices = list(kf.split(X))\n\n    rmse_scores = []\n\n    with xgboost.config_context(use_rmm=True):\n        for train_indices, val_indices in kf_indices:\n\n            X_train_fold, X_val_fold = X.iloc[train_indices], X.iloc[val_indices]\n            y_train_fold, y_val_fold = y[train_indices], y[val_indices]\n    \n            dtrain = xgboost.DMatrix(X_train_fold, label=y_train_fold)\n            dvalid = xgboost.DMatrix(X_val_fold, label=y_val_fold)\n    \n            xgb = xgboost.train(\n                params=param,\n                dtrain=dtrain,\n                num_boost_round=10000,\n                evals=[(dtrain, 'training'), (dvalid, 'validation')],\n                early_stopping_rounds=int(np.clip(100 / param[\"learning_rate\"], 20, 100)),\n                verbose_eval=False,\n            )\n    \n            rmse_scores.append(xgb.best_score)\n\n            del xgb # Free gpu memory\n            gc.collect()\n            cp.get_default_memory_pool().free_all_blocks()\n    \n    # Return mean float\n    return float(np.mean(rmse_scores))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CLEAR OUTPUT AFTER TRAINING \nclear_output(wait=True)\n\nsampler = optuna.samplers.TPESampler(\n    multivariate=True,      # Uses correlations between params\n    seed=42                 # Reproducible\n)\n\npruner = optuna.pruners.MedianPruner(\n    n_startup_trials=3,     # Let first few trials finish\n    n_warmup_steps=50,      # Wait before pruning\n    interval_steps=20       # Check pruning every N steps\n)\n\nstudy = optuna.create_study(\n    study_name='xgboost_study',\n    direction='minimize',\n    sampler=sampler,\n    pruner=pruner,\n    storage=\"sqlite:///xgb_study.db\",   # cleaner path\n    load_if_exists=True\n)\n\nstudy.optimize(\n    objective, \n    n_trials=50,                 # increase trials for real tuning\n    timeout=60 * 60 * 4,         # x-hour cap\n    show_progress_bar=True,\n    gc_after_trial=True,         # free GPU memory after each trial\n    n_jobs=1                    # n_jobs set to available GPU's\n)\n\nprint('Training Completed! Here are the insights:')\nbest_params = study.best_params\n\nprint(f'Total trials: {len(study.trials)}\\n')\n\nprint(\"Best Trial\", study.best_trial.number)\nprint(\"Best RMSE:\", study.best_value)\nprint(\"Best Params:\", study.best_trial.params)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Specify the path to the output file\nfile_path = 'xgb_study.db.'\n\n# Check if the file exists\nif os.path.exists(file_path):\n    # Remove the file\n    os.remove(file_path)\n    print(f\"{file_path} has been deleted.\")\nelse:\n    print(f\"{file_path} does not exist.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from plotly.io import show\n\nloaded_study = optuna.load_study(study_name=\"xgboost_study\", storage=\"sqlite:///xgb_study.db\")\nflg = optuna.visualization.plot_timeline(loaded_study)\nshow(flg)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:48:01.700469Z","iopub.execute_input":"2025-10-29T06:48:01.700830Z","iopub.status.idle":"2025-10-29T06:48:01.824751Z","shell.execute_reply.started":"2025-10-29T06:48:01.700803Z","shell.execute_reply":"2025-10-29T06:48:01.823729Z"}},"outputs":[{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f734c542-dbff-4091-b689-3bb12f189058\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f734c542-dbff-4091-b689-3bb12f189058\")) {                    Plotly.newPlot(                        \"f734c542-dbff-4091-b689-3bb12f189058\",                        [{\"base\":[\"2025-10-25T14:31:39.436179\",\"2025-10-25T14:32:52.150052\",\"2025-10-25T14:33:15.238766\",\"2025-10-25T14:34:34.835966\",\"2025-10-25T14:35:19.201288\",\"2025-10-25T14:36:16.366952\",\"2025-10-25T14:36:47.488046\",\"2025-10-25T14:38:46.767181\",\"2025-10-25T14:40:28.174879\",\"2025-10-25T14:50:24.531976\",\"2025-10-25T14:51:03.814530\",\"2025-10-25T14:52:19.485702\",\"2025-10-25T14:53:27.360842\",\"2025-10-25T14:54:09.849505\",\"2025-10-25T14:58:27.666135\",\"2025-10-25T15:01:15.220486\",\"2025-10-25T15:02:18.792318\",\"2025-10-25T15:04:35.857776\",\"2025-10-25T15:05:24.459424\",\"2025-10-25T15:11:25.156612\",\"2025-10-25T15:16:08.190361\",\"2025-10-25T15:22:12.157332\",\"2025-10-25T15:24:03.364102\",\"2025-10-25T15:29:51.140431\",\"2025-10-25T15:30:56.572544\",\"2025-10-25T15:35:52.438902\",\"2025-10-25T15:40:03.802820\",\"2025-10-25T15:42:43.157297\",\"2025-10-25T15:46:54.530522\",\"2025-10-25T15:47:56.347981\",\"2025-10-25T15:50:19.871866\",\"2025-10-25T15:51:15.984994\",\"2025-10-25T15:53:48.093516\",\"2025-10-25T15:56:32.354404\",\"2025-10-25T16:00:50.736259\",\"2025-10-25T16:01:47.881953\",\"2025-10-25T16:03:53.392015\",\"2025-10-25T16:06:27.645980\",\"2025-10-25T16:07:15.466061\",\"2025-10-25T16:08:53.906162\",\"2025-10-25T16:11:07.049576\",\"2025-10-25T16:15:27.351373\",\"2025-10-25T16:17:17.446286\",\"2025-10-25T16:20:11.490220\",\"2025-10-25T16:25:38.344771\",\"2025-10-25T16:26:46.835278\",\"2025-10-25T16:28:32.426840\",\"2025-10-25T16:33:10.718520\",\"2025-10-25T16:35:33.165470\",\"2025-10-25T16:36:34.827879\"],\"hovertemplate\":\"%{text}\\u003cextra\\u003eCOMPLETE\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":\"blue\"},\"name\":\"COMPLETE\",\"orientation\":\"h\",\"text\":[\"{\\u003cbr\\u003e  \\\"number\\\": 0,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.23815668394998\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.11423841529766665,\\u003cbr\\u003e    \\\"max_depth\\\": 9,\\u003cbr\\u003e    \\\"min_child_weight\\\": 5,\\u003cbr\\u003e    \\\"max_delta_step\\\": 5.986584841970366,\\u003cbr\\u003e    \\\"subsample\\\": 0.7046065241548528,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7045980821176709,\\u003cbr\\u003e    \\\"gamma\\\": 0.17425083650459838,\\u003cbr\\u003e    \\\"lambda\\\": 9.842315738502599,\\u003cbr\\u003e    \\\"alpha\\\": 2.416482602989751\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 1,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.57294830631781\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.21329755560542552,\\u003cbr\\u003e    \\\"max_depth\\\": 4,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 8.324426408004218,\\u003cbr\\u003e    \\\"subsample\\\": 0.7243186887373967,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7136387385224853,\\u003cbr\\u003e    \\\"gamma\\\": 0.5502135295603015,\\u003cbr\\u003e    \\\"lambda\\\": 0.5012686302434877,\\u003cbr\\u003e    \\\"alpha\\\": 1.6124278458562613\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 2,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.82566758087676\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.13128767053670837,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 4,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.3949386065204183,\\u003cbr\\u003e    \\\"subsample\\\": 0.7522506269873264,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7782266451527922,\\u003cbr\\u003e    \\\"gamma\\\": 1.3682099526511078,\\u003cbr\\u003e    \\\"lambda\\\": 6.407866261851015,\\u003cbr\\u003e    \\\"alpha\\\": 0.2880416977880551\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 3,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.13307460480743\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.15572762820884264,\\u003cbr\\u003e    \\\"max_depth\\\": 7,\\u003cbr\\u003e    \\\"min_child_weight\\\": 1,\\u003cbr\\u003e    \\\"max_delta_step\\\": 6.075448519014383,\\u003cbr\\u003e    \\\"subsample\\\": 0.7096834432905521,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6727680575448478,\\u003cbr\\u003e    \\\"gamma\\\": 2.84665661176,\\u003cbr\\u003e    \\\"lambda\\\": 16.670486450654682,\\u003cbr\\u003e    \\\"alpha\\\": 7.246804518258447\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 4,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.96794235664395\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0934702894444911,\\u003cbr\\u003e    \\\"max_depth\\\": 4,\\u003cbr\\u003e    \\\"min_child_weight\\\": 5,\\u003cbr\\u003e    \\\"max_delta_step\\\": 4.4015249373960135,\\u003cbr\\u003e    \\\"subsample\\\": 0.6927133821956726,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.8233119185389446,\\u003cbr\\u003e    \\\"gamma\\\": 0.10316556334565519,\\u003cbr\\u003e    \\\"lambda\\\": 12.370108840299013,\\u003cbr\\u003e    \\\"alpha\\\": 0.3939675937754722\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 5,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.30224826370153\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.19976911845313264,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 4,\\u003cbr\\u003e    \\\"max_delta_step\\\": 5.4671027934327965,\\u003cbr\\u003e    \\\"subsample\\\": 0.7146990594339345,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.9893546197175955,\\u003cbr\\u003e    \\\"gamma\\\": 2.3253984700833437,\\u003cbr\\u003e    \\\"lambda\\\": 14.514940016485882,\\u003cbr\\u003e    \\\"alpha\\\": 11.455777613940603\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 6,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.14823129705585\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.1805762937068923,\\u003cbr\\u003e    \\\"max_depth\\\": 9,\\u003cbr\\u003e    \\\"min_child_weight\\\": 1,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.959828624191452,\\u003cbr\\u003e    \\\"subsample\\\": 0.6658295511186884,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7638656157671425,\\u003cbr\\u003e    \\\"gamma\\\": 1.166031869068446,\\u003cbr\\u003e    \\\"lambda\\\": 0.42109711053281523,\\u003cbr\\u003e    \\\"alpha\\\": 8.071418522169695\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 7,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.76212423352809\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.10895573802799602,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 4,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.4092422497476265,\\u003cbr\\u003e    \\\"subsample\\\": 0.9307689432639139,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6760927252879199,\\u003cbr\\u003e    \\\"gamma\\\": 2.960660809801552,\\u003cbr\\u003e    \\\"lambda\\\": 5.983542473217019,\\u003cbr\\u003e    \\\"alpha\\\": 0.28658321062461245\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 8,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.751321673061895\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.004640068785709913,\\u003cbr\\u003e    \\\"max_depth\\\": 8,\\u003cbr\\u003e    \\\"min_child_weight\\\": 5,\\u003cbr\\u003e    \\\"max_delta_step\\\": 7.2900716804098735,\\u003cbr\\u003e    \\\"subsample\\\": 0.919944621340081,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6759156281069316,\\u003cbr\\u003e    \\\"gamma\\\": 1.0753971856328177,\\u003cbr\\u003e    \\\"lambda\\\": 0.18476435128841198,\\u003cbr\\u003e    \\\"alpha\\\": 9.683377710407786\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 9,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.153872483401585\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.1881195436677847,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 1,\\u003cbr\\u003e    \\\"max_delta_step\\\": 3.109823217156622,\\u003cbr\\u003e    \\\"subsample\\\": 0.7638141627093615,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.9053621624183225,\\u003cbr\\u003e    \\\"gamma\\\": 1.9126724140656393,\\u003cbr\\u003e    \\\"lambda\\\": 11.00279783199859,\\u003cbr\\u003e    \\\"alpha\\\": 1.2206206339370174\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 10,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.78799939804769\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.1272566034710647,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 1,\\u003cbr\\u003e    \\\"max_delta_step\\\": 2.069624016829401,\\u003cbr\\u003e    \\\"subsample\\\": 0.9074603007548878,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6984745513046663,\\u003cbr\\u003e    \\\"gamma\\\": 2.8544306555735877,\\u003cbr\\u003e    \\\"lambda\\\": 15.15157532800573,\\u003cbr\\u003e    \\\"alpha\\\": 0.15430160729506529\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 11,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.97971712417966\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.09821991608810106,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 3,\\u003cbr\\u003e    \\\"max_delta_step\\\": 4.209752065335729,\\u003cbr\\u003e    \\\"subsample\\\": 0.9906664350627489,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.755394070600974,\\u003cbr\\u003e    \\\"gamma\\\": 2.5714219663941282,\\u003cbr\\u003e    \\\"lambda\\\": 15.119009626559627,\\u003cbr\\u003e    \\\"alpha\\\": 0.6929254345452142\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 12,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.16324318902594\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.22933192551853845,\\u003cbr\\u003e    \\\"max_depth\\\": 4,\\u003cbr\\u003e    \\\"min_child_weight\\\": 1,\\u003cbr\\u003e    \\\"max_delta_step\\\": 2.0944192311585637,\\u003cbr\\u003e    \\\"subsample\\\": 0.9096227359818044,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7621615857451955,\\u003cbr\\u003e    \\\"gamma\\\": 2.354307611017957,\\u003cbr\\u003e    \\\"lambda\\\": 9.888448486701353,\\u003cbr\\u003e    \\\"alpha\\\": 0.13788318064936805\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 13,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.46459331539329\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.023712229969983414,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 2,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.3561104815070535,\\u003cbr\\u003e    \\\"subsample\\\": 0.8172455044302813,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6805204213975329,\\u003cbr\\u003e    \\\"gamma\\\": 2.372267881106462,\\u003cbr\\u003e    \\\"lambda\\\": 2.401876508617636,\\u003cbr\\u003e    \\\"alpha\\\": 0.13824673396349108\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 14,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.70779050857984\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.19934002708596332,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 4,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.4359531872569582,\\u003cbr\\u003e    \\\"subsample\\\": 0.9504734004490338,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6551936735375731,\\u003cbr\\u003e    \\\"gamma\\\": 2.9979743700506827,\\u003cbr\\u003e    \\\"lambda\\\": 1.775412729598054,\\u003cbr\\u003e    \\\"alpha\\\": 0.7225565341048951\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 15,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.23291556527906\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.24292131759990088,\\u003cbr\\u003e    \\\"max_depth\\\": 8,\\u003cbr\\u003e    \\\"min_child_weight\\\": 5,\\u003cbr\\u003e    \\\"max_delta_step\\\": 2.202812319429748,\\u003cbr\\u003e    \\\"subsample\\\": 0.8413692324849944,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7014952774226023,\\u003cbr\\u003e    \\\"gamma\\\": 2.4921015597690968,\\u003cbr\\u003e    \\\"lambda\\\": 1.9607493165163121,\\u003cbr\\u003e    \\\"alpha\\\": 0.334796797695432\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 16,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.96612416352269\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.2586462478613083,\\u003cbr\\u003e    \\\"max_depth\\\": 4,\\u003cbr\\u003e    \\\"min_child_weight\\\": 5,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.28536795567852213,\\u003cbr\\u003e    \\\"subsample\\\": 0.969027831629246,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7080878214749342,\\u003cbr\\u003e    \\\"gamma\\\": 2.1485159067058888,\\u003cbr\\u003e    \\\"lambda\\\": 2.63569094416964,\\u003cbr\\u003e    \\\"alpha\\\": 1.9544253584750677\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 17,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.98821235136516\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.17093269748668044,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 4,\\u003cbr\\u003e    \\\"max_delta_step\\\": 2.36338642878284,\\u003cbr\\u003e    \\\"subsample\\\": 0.9539539128892728,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6801770862254807,\\u003cbr\\u003e    \\\"gamma\\\": 2.7950470862606323,\\u003cbr\\u003e    \\\"lambda\\\": 0.3143559976402619,\\u003cbr\\u003e    \\\"alpha\\\": 0.19492937444063532\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 18,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    42.81652313427586\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.10918918066923938,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 5,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.1401691893942847,\\u003cbr\\u003e    \\\"subsample\\\": 0.9438773633538823,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6684387255337185,\\u003cbr\\u003e    \\\"gamma\\\": 1.592771200959777,\\u003cbr\\u003e    \\\"lambda\\\": 3.998365238452839,\\u003cbr\\u003e    \\\"alpha\\\": 0.14657250236989927\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 19,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.747281877964795\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.11615250344694567,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.4082183332595779,\\u003cbr\\u003e    \\\"subsample\\\": 0.9698250591382854,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6520703784727968,\\u003cbr\\u003e    \\\"gamma\\\": 2.8982612509561614,\\u003cbr\\u003e    \\\"lambda\\\": 4.358766855799142,\\u003cbr\\u003e    \\\"alpha\\\": 2.1820622261248825\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 20,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    40.035316010046486\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.08202602657432391,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 5,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.23529807157121624,\\u003cbr\\u003e    \\\"subsample\\\": 0.9844258892438729,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6899513529129129,\\u003cbr\\u003e    \\\"gamma\\\": 2.781069763510747,\\u003cbr\\u003e    \\\"lambda\\\": 7.790426662116329,\\u003cbr\\u003e    \\\"alpha\\\": 8.494585535106651\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 21,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.81976041905178\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.051432056194491524,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 4.985038146726796,\\u003cbr\\u003e    \\\"subsample\\\": 0.9730198836974591,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.651200753368112,\\u003cbr\\u003e    \\\"gamma\\\": 2.7133903617510526,\\u003cbr\\u003e    \\\"lambda\\\": 3.6357970025075836,\\u003cbr\\u003e    \\\"alpha\\\": 0.6506184807575349\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 22,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.78990007706514\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.08629039756524351,\\u003cbr\\u003e    \\\"max_depth\\\": 8,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.8101544284915883,\\u003cbr\\u003e    \\\"subsample\\\": 0.7941377854496483,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6538100884445168,\\u003cbr\\u003e    \\\"gamma\\\": 2.9814574457826652,\\u003cbr\\u003e    \\\"lambda\\\": 3.991508706019272,\\u003cbr\\u003e    \\\"alpha\\\": 3.296917176034715\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 23,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.10432117031118\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.22468298565006933,\\u003cbr\\u003e    \\\"max_depth\\\": 7,\\u003cbr\\u003e    \\\"min_child_weight\\\": 4,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.7376981611585358,\\u003cbr\\u003e    \\\"subsample\\\": 0.9500157831201465,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6744253859507472,\\u003cbr\\u003e    \\\"gamma\\\": 2.5998613301014872,\\u003cbr\\u003e    \\\"lambda\\\": 3.3463000116233883,\\u003cbr\\u003e    \\\"alpha\\\": 1.1729169780548052\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 24,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.69960842319517\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.1551315397027822,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.2968100656986642,\\u003cbr\\u003e    \\\"subsample\\\": 0.9574630964578006,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7129776326652996,\\u003cbr\\u003e    \\\"gamma\\\": 2.7194155110374623,\\u003cbr\\u003e    \\\"lambda\\\": 8.68756617395945,\\u003cbr\\u003e    \\\"alpha\\\": 1.336772249024356\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 25,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.83913291798146\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.09452628182561561,\\u003cbr\\u003e    \\\"max_depth\\\": 7,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.7665811019021405,\\u003cbr\\u003e    \\\"subsample\\\": 0.9285704472732359,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7468934395835414,\\u003cbr\\u003e    \\\"gamma\\\": 2.7577466646175965,\\u003cbr\\u003e    \\\"lambda\\\": 10.75044423818943,\\u003cbr\\u003e    \\\"alpha\\\": 0.3433759294246266\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 26,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.67638275307648\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.07568164224284057,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 3,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.2134886836690164,\\u003cbr\\u003e    \\\"subsample\\\": 0.8975379334267904,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6748205604474841,\\u003cbr\\u003e    \\\"gamma\\\": 2.60078368985854,\\u003cbr\\u003e    \\\"lambda\\\": 0.6529665937267058,\\u003cbr\\u003e    \\\"alpha\\\": 3.0538914544759876\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 27,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    78.44648190729639\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.026609654779531297,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 2,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.09061566457024894,\\u003cbr\\u003e    \\\"subsample\\\": 0.8874646509707848,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7303329800394655,\\u003cbr\\u003e    \\\"gamma\\\": 2.4643503772547333,\\u003cbr\\u003e    \\\"lambda\\\": 0.22925472202030045,\\u003cbr\\u003e    \\\"alpha\\\": 3.7648392166307585\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 28,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.90949665691288\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.14795130325950884,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 2,\\u003cbr\\u003e    \\\"max_delta_step\\\": 2.6502037700428964,\\u003cbr\\u003e    \\\"subsample\\\": 0.8790897522894411,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6688069564452646,\\u003cbr\\u003e    \\\"gamma\\\": 2.5741592704643894,\\u003cbr\\u003e    \\\"lambda\\\": 0.5528214474295826,\\u003cbr\\u003e    \\\"alpha\\\": 3.6407399025034817\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 29,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.74759578143649\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.06654087449942343,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 4,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.9592155942195695,\\u003cbr\\u003e    \\\"subsample\\\": 0.9598171416876768,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6844294035758525,\\u003cbr\\u003e    \\\"gamma\\\": 2.8180778969887927,\\u003cbr\\u003e    \\\"lambda\\\": 0.20744368933268814,\\u003cbr\\u003e    \\\"alpha\\\": 2.409742521743246\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 30,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.13583343093124\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.18504985609716534,\\u003cbr\\u003e    \\\"max_depth\\\": 4,\\u003cbr\\u003e    \\\"min_child_weight\\\": 5,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.35880269821742,\\u003cbr\\u003e    \\\"subsample\\\": 0.8907740832555733,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7749094334157873,\\u003cbr\\u003e    \\\"gamma\\\": 2.848369228231846,\\u003cbr\\u003e    \\\"lambda\\\": 10.725269487005555,\\u003cbr\\u003e    \\\"alpha\\\": 0.8493113481211452\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 31,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.93215176281389\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.077640432381199,\\u003cbr\\u003e    \\\"max_depth\\\": 4,\\u003cbr\\u003e    \\\"min_child_weight\\\": 1,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.3146834372590885,\\u003cbr\\u003e    \\\"subsample\\\": 0.9581637661313268,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6557774507332921,\\u003cbr\\u003e    \\\"gamma\\\": 2.5817986063204925,\\u003cbr\\u003e    \\\"lambda\\\": 2.742599835220335,\\u003cbr\\u003e    \\\"alpha\\\": 1.9994638231103472\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 32,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.746461368630236\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.17139686727040443,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 3,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.5388182155968361,\\u003cbr\\u003e    \\\"subsample\\\": 0.9667781721451844,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7168284177933031,\\u003cbr\\u003e    \\\"gamma\\\": 2.8502299804749485,\\u003cbr\\u003e    \\\"lambda\\\": 1.5982760731699313,\\u003cbr\\u003e    \\\"alpha\\\": 0.8895066976657228\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 33,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    40.29899763734612\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.2206673046621421,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 3,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.09188208701279427,\\u003cbr\\u003e    \\\"subsample\\\": 0.9966877314324193,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6883909503311131,\\u003cbr\\u003e    \\\"gamma\\\": 2.75884255718018,\\u003cbr\\u003e    \\\"lambda\\\": 1.2028039554328607,\\u003cbr\\u003e    \\\"alpha\\\": 1.2435312699212524\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 34,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.98371300158009\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.1458504634352633,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 2,\\u003cbr\\u003e    \\\"max_delta_step\\\": 2.283905873033575,\\u003cbr\\u003e    \\\"subsample\\\": 0.8739216642980326,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.9345513019784221,\\u003cbr\\u003e    \\\"gamma\\\": 2.640078704168065,\\u003cbr\\u003e    \\\"lambda\\\": 1.12711460367357,\\u003cbr\\u003e    \\\"alpha\\\": 19.9252723017086\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 35,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.21698158182541\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.10364732466413146,\\u003cbr\\u003e    \\\"max_depth\\\": 8,\\u003cbr\\u003e    \\\"min_child_weight\\\": 3,\\u003cbr\\u003e    \\\"max_delta_step\\\": 2.829699864960401,\\u003cbr\\u003e    \\\"subsample\\\": 0.9891776295218135,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7384313798209833,\\u003cbr\\u003e    \\\"gamma\\\": 2.2312087585873397,\\u003cbr\\u003e    \\\"lambda\\\": 1.1825254469769393,\\u003cbr\\u003e    \\\"alpha\\\": 2.572661038780017\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 36,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.80007143257522\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.16499205893907834,\\u003cbr\\u003e    \\\"max_depth\\\": 7,\\u003cbr\\u003e    \\\"min_child_weight\\\": 3,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.7876070868890637,\\u003cbr\\u003e    \\\"subsample\\\": 0.9106059440349912,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.826014309260253,\\u003cbr\\u003e    \\\"gamma\\\": 2.7700524843164454,\\u003cbr\\u003e    \\\"lambda\\\": 0.8352600043401818,\\u003cbr\\u003e    \\\"alpha\\\": 0.5553990068197348\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 37,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.21307936822619\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.20249701691595481,\\u003cbr\\u003e    \\\"max_depth\\\": 7,\\u003cbr\\u003e    \\\"min_child_weight\\\": 2,\\u003cbr\\u003e    \\\"max_delta_step\\\": 3.2603571412129027,\\u003cbr\\u003e    \\\"subsample\\\": 0.9321605159092123,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.728635431070323,\\u003cbr\\u003e    \\\"gamma\\\": 1.3995507999071557,\\u003cbr\\u003e    \\\"lambda\\\": 0.8981186491849669,\\u003cbr\\u003e    \\\"alpha\\\": 0.3931341743684144\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 38,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.78048671740522\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.14382939121024443,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.3389992122728431,\\u003cbr\\u003e    \\\"subsample\\\": 0.9582659305764587,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7161590422844231,\\u003cbr\\u003e    \\\"gamma\\\": 1.9173906400386782,\\u003cbr\\u003e    \\\"lambda\\\": 18.684108681683124,\\u003cbr\\u003e    \\\"alpha\\\": 0.7870752740925919\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 39,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.87481633661547\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.14460767150827986,\\u003cbr\\u003e    \\\"max_depth\\\": 7,\\u003cbr\\u003e    \\\"min_child_weight\\\": 4,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.1558241765022985,\\u003cbr\\u003e    \\\"subsample\\\": 0.9041959382309739,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6926967176718526,\\u003cbr\\u003e    \\\"gamma\\\": 2.8201189917899434,\\u003cbr\\u003e    \\\"lambda\\\": 0.5517282838253322,\\u003cbr\\u003e    \\\"alpha\\\": 0.4652094324565314\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 40,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    38.55854669061064\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.045082754684333405,\\u003cbr\\u003e    \\\"max_depth\\\": 5,\\u003cbr\\u003e    \\\"min_child_weight\\\": 3,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.6463072451452533,\\u003cbr\\u003e    \\\"subsample\\\": 0.8152456088367105,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7317694485487726,\\u003cbr\\u003e    \\\"gamma\\\": 1.9342385663959067,\\u003cbr\\u003e    \\\"lambda\\\": 1.6637135698321506,\\u003cbr\\u003e    \\\"alpha\\\": 2.01094953278845\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 41,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.74992584638499\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.1350638038097532,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 4,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.12624156189746,\\u003cbr\\u003e    \\\"subsample\\\": 0.9309363448612759,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6590527181862452,\\u003cbr\\u003e    \\\"gamma\\\": 2.728570746398426,\\u003cbr\\u003e    \\\"lambda\\\": 1.411819410092107,\\u003cbr\\u003e    \\\"alpha\\\": 1.8283044160238078\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 42,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.8995571028489\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.12993609569029133,\\u003cbr\\u003e    \\\"max_depth\\\": 7,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.853753598509568,\\u003cbr\\u003e    \\\"subsample\\\": 0.9842293976385614,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.675753054489182,\\u003cbr\\u003e    \\\"gamma\\\": 2.752829900768616,\\u003cbr\\u003e    \\\"lambda\\\": 7.217707997142835,\\u003cbr\\u003e    \\\"alpha\\\": 2.599351339699406\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 43,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.65678522362444\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.16186921257363845,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.26624448580987936,\\u003cbr\\u003e    \\\"subsample\\\": 0.8897218397722685,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7188172466872444,\\u003cbr\\u003e    \\\"gamma\\\": 2.4632570628465293,\\u003cbr\\u003e    \\\"lambda\\\": 2.338564224704382,\\u003cbr\\u003e    \\\"alpha\\\": 1.2430282936492325\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 44,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.86419932224038\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.2071745441138933,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.2944290763545787,\\u003cbr\\u003e    \\\"subsample\\\": 0.8650669408479031,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7972788808807381,\\u003cbr\\u003e    \\\"gamma\\\": 2.6050649158196815,\\u003cbr\\u003e    \\\"lambda\\\": 2.4446528621909027,\\u003cbr\\u003e    \\\"alpha\\\": 0.3319342796773661\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 45,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.9038322719897\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.09811210940453002,\\u003cbr\\u003e    \\\"max_depth\\\": 4,\\u003cbr\\u003e    \\\"min_child_weight\\\": 4,\\u003cbr\\u003e    \\\"max_delta_step\\\": 1.4696389439543909,\\u003cbr\\u003e    \\\"subsample\\\": 0.9092355537139222,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.6896328683629935,\\u003cbr\\u003e    \\\"gamma\\\": 2.139222689066343,\\u003cbr\\u003e    \\\"lambda\\\": 1.1899712554712083,\\u003cbr\\u003e    \\\"alpha\\\": 7.844092935891279\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 46,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.70401590594176\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.14824781924530367,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.34985280374537686,\\u003cbr\\u003e    \\\"subsample\\\": 0.7507731698994948,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.8332032472402768,\\u003cbr\\u003e    \\\"gamma\\\": 2.129508623996384,\\u003cbr\\u003e    \\\"lambda\\\": 2.4001634868122177,\\u003cbr\\u003e    \\\"alpha\\\": 1.2392058442265226\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 47,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.73330101767904\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.12111062922007754,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.9034759180696802,\\u003cbr\\u003e    \\\"subsample\\\": 0.7284678684220192,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.8501419589472506,\\u003cbr\\u003e    \\\"gamma\\\": 2.2345990088954615,\\u003cbr\\u003e    \\\"lambda\\\": 3.2752886725766475,\\u003cbr\\u003e    \\\"alpha\\\": 2.2130398388213974\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 48,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    37.90185185487695\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.1559722439148062,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 2.115436761816177,\\u003cbr\\u003e    \\\"subsample\\\": 0.8856113672524878,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.7752177817491351,\\u003cbr\\u003e    \\\"gamma\\\": 2.414110396694985,\\u003cbr\\u003e    \\\"lambda\\\": 2.3571486537999253,\\u003cbr\\u003e    \\\"alpha\\\": 3.142719748392016\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 49,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    42.29873051037855\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"learning_rate\\\": 0.08160467390300913,\\u003cbr\\u003e    \\\"max_depth\\\": 6,\\u003cbr\\u003e    \\\"min_child_weight\\\": 6,\\u003cbr\\u003e    \\\"max_delta_step\\\": 0.19648736547347173,\\u003cbr\\u003e    \\\"subsample\\\": 0.8505559663623189,\\u003cbr\\u003e    \\\"colsample_bytree\\\": 0.8483451569205263,\\u003cbr\\u003e    \\\"gamma\\\": 1.6079492572015526,\\u003cbr\\u003e    \\\"lambda\\\": 5.343482782338071,\\u003cbr\\u003e    \\\"alpha\\\": 0.6354290029006562\\u003cbr\\u003e  }\\u003cbr\\u003e}\"],\"textposition\":\"none\",\"x\":[72163.289,22528.671,79035.231,43825.289,56624.946,30559.707,118731.455,100868.682,595788.466,38705.316000000006,75105.678,67294.86,41909.182,257243.59,166971.369,62995.046,136487.66499999998,47996.311,360126.397,282436.02800000005,363392.237,110640.895,347195.91500000004,64862.725999999995,295303.21099999995,250798.216,158802.703,250777.637,61244.397,142960.186,55550.894,151539.335,163686.77099999998,257817.769,56574.979999999996,124942.47300000001,153685.31100000002,47248.239,97864.062,132565.231,259735.549,109517.856,173477.973,326311.439,67950.223,105067.49100000001,277740.252,141901.49500000002,61122.495,355417.824],\"y\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"type\":\"date\",\"title\":{\"text\":\"Datetime\"}},\"title\":{\"text\":\"Timeline Plot\"},\"yaxis\":{\"title\":{\"text\":\"Trial\"}},\"showlegend\":true},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('f734c542-dbff-4091-b689-3bb12f189058');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"fig = optuna.visualization.plot_param_importances(loaded_study)\nshow(fig)\nimportance = pd.DataFrame({\n    'Name': fig.data[0]['y'],\n    'Importance': fig.data[0]['x']\n}).sort_values(by=['Importance'], ascending=False).reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"flg = optuna.visualization.plot_optimization_history(loaded_study)\nshow(flg)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loaded_study.best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T06:48:54.313521Z","iopub.execute_input":"2025-10-29T06:48:54.313910Z","iopub.status.idle":"2025-10-29T06:48:54.336259Z","shell.execute_reply.started":"2025-10-29T06:48:54.313874Z","shell.execute_reply":"2025-10-29T06:48:54.335297Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'learning_rate': 0.16186921257363845,\n 'max_depth': 6,\n 'min_child_weight': 6,\n 'max_delta_step': 0.26624448580987936,\n 'subsample': 0.8897218397722685,\n 'colsample_bytree': 0.7188172466872444,\n 'gamma': 2.4632570628465293,\n 'lambda': 2.338564224704382,\n 'alpha': 1.2430282936492325}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"flg = optuna.visualization.plot_contour(\n    loaded_study, \n    params=['max_delta_step', 'max_depth'], \n    target_name='RMSE'\n)\nshow(flg)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UMAP Paramater Visualization","metadata":{}},{"cell_type":"code","source":"rows = []\nfor trial in loaded_study.trials:\n    if trial.state == optuna.trial.TrialState.COMPLETE:\n        row = {\n            'trial_number': trial.number,\n            'value': trial.value,\n            'state': trial.state.name,\n            'duration': trial.duration.total_seconds() if trial.duration else None\n        }\n        # Merge parameters\n        row.update(trial.params)\n        rows.append(row)\n\ndf = pd.DataFrame(rows)\ndf.sort_values(['colsample_bytree'], ascending=True).reset_index().head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## import pandas as pd\nfrom umap import UMAP\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.express as px\n\n# --- Prepare features ---\nX = df.drop(columns=['trial_number', 'state', 'duration', 'value'], errors='ignore')\ny = df['value']\n\n# Optional: log-transform positive-only parameters\nfor c in X.columns:\n    if (X[c] > 0).all() and X[c].max() / X[c].min() > 100:\n        X[c] = np.log1p(X[c])\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# --- Tune UMAP for your dataset ---\numap = UMAP(\n    n_components=2,\n    n_neighbors=10,     # smaller -> focus on local clusters, larger -> global trends\n    min_dist=0.1,       # larger -> more spread out, smaller -> tighter clusters\n    metric='euclidean',\n    random_state=42\n)\nX_embedded = umap.fit_transform(X_scaled)\n\n# --- Plot ---\nvis_df = pd.DataFrame({\n    'umap_x': X_embedded[:, 0],\n    'umap_y': X_embedded[:, 1],\n    'RMSE': y\n})\nimport numpy as np\nimport plotly.express as px\n\n# We'll assume you already have vis_df with umap_x, umap_y, and RMSE columns\nbest_threshold = np.percentile(vis_df['RMSE'], 5)  # top 10% best (lowest RMSE)\n\nvis_df['is_best'] = vis_df['RMSE'] <= best_threshold\n\nfig = px.scatter(\n    vis_df,\n    x='umap_x',\n    y='umap_y',\n    color='RMSE',\n    color_continuous_scale='Viridis_r',  # reverse so low RMSE = bright\n    symbol='is_best',\n    symbol_map={True: 'star', False: 'circle'},\n    size=np.where(vis_df['is_best'], 10, 2),\n    opacity=0.8,\n    title='UMAP Visualization of Optuna Trials (Best Results Highlighted)',\n    hover_data=['RMSE']\n)\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}